import streamlit as st
from google import genai
from google.genai import types
from pypdf import PdfReader
import os
import gdown

# Configura√ß√£o da P√°gina
st.set_page_config(
    page_title="Harvard Mentor AI",
    page_icon="üéì",
    layout="wide"
)

# --- 1. CONFIGURA√á√ÉO DE SEGREDOS ---
api_key = st.secrets.get("GOOGLE_API_KEY")
file_id = st.secrets.get("GDRIVE_FILE_ID")

# --- 2. FUN√á√ïES DE INFRAESTRUTURA ---

def download_pdf_if_needed(filename):
    """Verifica se o PDF existe ou baixa do Drive."""
    if os.path.exists(filename):
        return True
    
    if not file_id:
        st.error("Erro: ID do arquivo n√£o configurado nos Secrets.")
        return False

    with st.spinner("Baixando material de estudo seguro..."):
        try:
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, filename, quiet=False)
            return True
        except Exception as e:
            st.error(f"Falha ao baixar o arquivo: {e}")
            return False

@st.cache_resource
def load_pdf_text(pdf_path):
    """L√™ o PDF e extrai o texto."""
    if not download_pdf_if_needed(pdf_path):
        return None
    
    try:
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        st.error(f"Erro ao ler PDF: {e}")
        return None

def get_gemini_response(chat_history_streamlit, mode, context_text):
    """
    Nova fun√ß√£o usando o SDK google-genai atualizado.
    """
    
    # 1. Defini√ß√£o do System Prompt (Instru√ß√µes)
    prompts = {
        "Consultor": f"""
            Voc√™ √© um Consultor S√™nior da Harvard Business School.
            CONTEXTO: O usu√°rio tem um desafio de neg√≥cios.
            BASE DE CONHECIMENTO: Use EXCLUSIVAMENTE o seguinte material: {context_text}
            DIRETRIZES: Analise o problema, cite o conceito do texto e d√™ um plano de a√ß√£o.
            """,
        "Quiz": f"""
            Voc√™ √© um Professor avaliador.
            BASE DE CONHECIMENTO: {context_text}
            DIRETRIZES: Fa√ßa uma pergunta baseada no texto. Se o usu√°rio responder, avalie e explique.
            """,
        "Roleplay": f"""
            ATEN√á√ÉO: Voc√™ √© um PERSONAGEM em uma simula√ß√£o.
            CEN√ÅRIO: Baseado em: {context_text}
            DIRETRIZES: Aja como uma contraparte dif√≠cil. N√£o saia do personagem.
            """
    }
    
    system_instruction = prompts.get(mode, "Voc√™ √© um assistente √∫til.")

    # 2. Inicializa o Cliente (Nova Sintaxe)
    client = genai.Client(api_key=api_key)

    # 3. Converte hist√≥rico do Streamlit para o formato da Google
    # Streamlit usa: {"role": "user/assistant", "content": "texto"}
    # Google GenAI usa: types.Content(role="user/model", parts=[...])
    
    contents = []
    for msg in chat_history_streamlit:
        role = "user" if msg["role"] == "user" else "model"
        contents.append(
            types.Content(
                role=role,
                parts=[types.Part.from_text(text=msg["content"])]
            )
        )

    # 4. Configura√ß√£o da Gera√ß√£o
    generate_content_config = types.GenerateContentConfig(
        temperature=0.7,
        top_p=0.95,
        max_output_tokens=2000,
        system_instruction=system_instruction,
    )

    # 5. Chamada ao Modelo
    try:
        response = client.models.generate_content(
            model="gemini-1.5-flash",
            contents=contents,
            config=generate_content_config
        )
        return response.text
    except Exception as e:
        return f"Erro na API Google: {str(e)}"

# --- 3. INTERFACE (FRONTEND) ---

st.sidebar.title("Harvard Impact AI")
page = st.sidebar.radio("Menu", ["Introdu√ß√£o", "Mentor Virtual"])

if page == "Introdu√ß√£o":
    st.title("Domine os Fundamentos de Neg√≥cios üöÄ")
    st.markdown("""
    Bem-vindo ao seu Mentor de Neg√≥cios baseado no curr√≠culo de Harvard.
    Utilizando a tecnologia **Google Gemini 1.5 Flash**.
    
    Escolha seu modo no menu lateral:
    1.  **Consultor:** Resolu√ß√£o de problemas.
    2.  **Quiz:** Estudo ativo.
    3.  **Roleplay:** Simula√ß√£o pr√°tica.
    """)

elif page == "Mentor Virtual":
    if not api_key:
        st.warning("‚ö†Ô∏è API Key n√£o detectada nos Secrets.")
        st.stop()
    
    pdf_filename = "Harvard Manager Mentor.pdf"
    pdf_text = load_pdf_text(pdf_filename)
    
    if not pdf_text:
        st.stop()

    col1, col2 = st.columns([3, 1])
    with col1:
        mode = st.radio("Modo:", ["Consultor", "Quiz", "Roleplay"], horizontal=True)
    with col2:
        if st.button("Limpar Chat üóëÔ∏è"):
            st.session_state.messages = []
            st.rerun()

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        avatar = "ü§ñ" if message["role"] == "assistant" else "üë§"
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"])

    if prompt := st.chat_input("Digite sua mensagem..."):
        # Adiciona mensagem do usu√°rio ao hist√≥rico visual
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üë§"):
            st.markdown(prompt)

        with st.chat_message("assistant", avatar="ü§ñ"):
            with st.spinner("Analisando..."):
                # Passa o hist√≥rico completo + nova mensagem (j√° inclusa no state)
                response_text = get_gemini_response(st.session_state.messages, mode, pdf_text)
                
                st.markdown(response_text)
                st.session_state.messages.append({"role": "assistant", "content": response_text})

# --- DEBUG: LISTAR MODELOS DISPON√çVEIS ---
# Coloque isso temporariamente no seu c√≥digo para ver a lista real
with st.sidebar.expander("üîß Debug: Modelos Dispon√≠veis"):
    try:
        client = genai.Client(api_key=api_key)
        # Tenta listar os modelos
        models = client.models.list()
        for m in models:
            # Filtra apenas os que geram texto
            if "generateContent" in m.supported_generation_methods:
                st.code(m.name.replace("models/", ""))
    except Exception as e:
        st.error(f"Erro ao listar modelos: {e}")
