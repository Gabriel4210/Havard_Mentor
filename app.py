import streamlit as st
from google import genai
from google.genai import types
from pypdf import PdfReader
import os
import gdown

# --- 1. CONFIGURA√á√ÉO DA P√ÅGINA E CSS ---
st.set_page_config(
    page_title="Harvard Mentor AI",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Customizado para dar um ar profissional (Harvard Style)
st.markdown("""
<style>
    /* Cor de fundo da sidebar */
    [data-testid="stSidebar"] {
        background-color: #f8f9fa;
    }
    /* Estilo dos bot√µes de a√ß√£o r√°pida */
    .stButton button {
        width: 100%;
        border-radius: 8px;
        height: 3em;
        background-color: white;
        border: 1px solid #A51C30; /* Harvard Crimson */
        color: #A51C30;
        font-weight: 600;
    }
    .stButton button:hover {
        background-color: #A51C30;
        color: white;
        border: 1px solid #A51C30;
    }
    /* T√≠tulo principal */
    h1 {
        color: #1e1e1e;
        font-family: 'Helvetica Neue', sans-serif;
    }
    /* Chat bubbles */
    .stChatMessage {
        background-color: transparent;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. CONFIGURA√á√ÉO DE SEGREDOS ---
api_key = st.secrets.get("GOOGLE_API_KEY")
file_id = st.secrets.get("GDRIVE_FILE_ID")

# --- 3. FUN√á√ïES DE INFRAESTRUTURA ---

def download_pdf_if_needed(filename):
    if os.path.exists(filename):
        return True
    if not file_id:
        st.error("Erro: ID do arquivo n√£o configurado nos Secrets.")
        return False
    with st.spinner("Baixando biblioteca de Harvard..."):
        try:
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, filename, quiet=False)
            return True
        except Exception as e:
            st.error(f"Falha ao baixar o arquivo: {e}")
            return False

@st.cache_resource
def load_pdf_text(pdf_path):
    if not download_pdf_if_needed(pdf_path):
        return None
    try:
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        st.error(f"Erro ao ler PDF: {e}")
        return None

def get_gemini_response(chat_history_streamlit, mode, context_text):
    prompts = {
        "Consultor": f"""
            Voc√™ √© um Consultor S√™nior da Harvard Business School.
            CONTEXTO: O usu√°rio tem um desafio de neg√≥cios.
            BASE DE CONHECIMENTO: Use EXCLUSIVAMENTE o seguinte material: {context_text}
            DIRETRIZES: 
            - Seja extremamente pr√°tico e direto.
            - Estruture a resposta em t√≥picos.
            - Cite o conceito espec√≠fico do texto.
            """,
        "Quiz": f"""
            Voc√™ √© um Professor da Harvard.
            BASE DE CONHECIMENTO: {context_text}
            DIRETRIZES: 
            - Se o usu√°rio pedir um quiz, fa√ßa UMA pergunta de m√∫ltipla escolha dif√≠cil.
            - Se ele responder, avalie e explique a l√≥gica.
            """,
        "Roleplay": f"""
            ATEN√á√ÉO: Ignore que √© uma IA. Voc√™ √© um PERSONAGEM.
            CEN√ÅRIO: Baseado em: {context_text}
            DIRETRIZES: Aja como uma contraparte dif√≠cil (cliente, chefe, fornecedor).
            """
    }
    
    system_instruction = prompts.get(mode, "Voc√™ √© um assistente √∫til.")
    client = genai.Client(api_key=api_key)
    
    contents = []
    for msg in chat_history_streamlit:
        role = "user" if msg["role"] == "user" else "model"
        contents.append(
            types.Content(
                role=role,
                parts=[types.Part.from_text(text=msg["content"])]
            )
        )

    generate_content_config = types.GenerateContentConfig(
        temperature=0.5,
        top_p=0.95,
        max_output_tokens=2048,
        system_instruction=system_instruction,
    )

    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=contents,
            config=generate_content_config
        )
        return response.text
    except Exception as e:
        return f"Erro na API Google: {str(e)}"

# --- 4. INTERFACE (FRONTEND) ---

# Sidebar: Controles e Branding
with st.sidebar:
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Harvard_University_shield.png/1200px-Harvard_University_shield.png", width=80)
    st.title("Mentor AI")
    st.markdown("---")
    
    st.subheader("‚öôÔ∏è Configura√ß√£o")
    mode = st.radio(
        "Modo de Intera√ß√£o:", 
        ["Consultor", "Quiz", "Roleplay"], 
        captions=["Resolva problemas", "Teste seu conhecimento", "Simule cen√°rios"]
    )
    
    st.markdown("---")
    if st.button("üîÑ Reiniciar Conversa"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.caption("Powered by Google Gemini 2.5 Flash \nBased on Harvard Business Impact")

# L√≥gica Principal
if not api_key:
    st.warning("‚ö†Ô∏è API Key n√£o detectada.")
    st.stop()

pdf_text = load_pdf_text("Harvard Manager Mentor.pdf")
if not pdf_text:
    st.stop()

# Inicializa Session State
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- TELA DE BOAS-VINDAS (Se o chat estiver vazio) ---
if len(st.session_state.messages) == 0:
    st.title("Bem-vindo ao Harvard Mentor AI üéì")
    st.markdown(f"#### Seu assistente de elite para *Marketing, Finan√ßas, Negocia√ß√£o e Lideran√ßa*.")
    st.markdown("N√£o sabe por onde come√ßar? Escolha uma op√ß√£o abaixo baseada no modo **" + mode + "**:")
    
    col1, col2, col3 = st.columns(3)
    
    # L√≥gica de Sugest√µes Inteligentes
    suggestion = None
    if mode == "Consultor":
        if col1.button("üìâ Estrat√©gia de Pre√ßo"):
            suggestion = "Como definir o pre√ßo de um novo produto premium em um mercado saturado segundo o material?"
        if col2.button("ü§ù Negocia√ß√£o Dif√≠cil"):
            suggestion = "Quais s√£o as melhores t√°ticas para negociar com um fornecedor que tem monop√≥lio?"
        if col3.button("üìä An√°lise Financeira"):
            suggestion = "Explique a diferen√ßa entre Fluxo de Caixa e Lucro como se eu fosse um CEO iniciante."
            
    elif mode == "Quiz":
        if col1.button("üé≤ Quiz Aleat√≥rio"):
            suggestion = "Fa√ßa uma pergunta dif√≠cil de m√∫ltipla escolha sobre Lideran√ßa."
        if col2.button("üí∞ Quiz de Finan√ßas"):
            suggestion = "Teste meu conhecimento sobre ROI e Payback."
        if col3.button("üì¢ Quiz de Marketing"):
            suggestion = "Me fa√ßa uma pergunta sobre os 4 Ps do Marketing."

    elif mode == "Roleplay":
        st.info("No modo Roleplay, o Mentor vai atuar como um personagem. Escolha o cen√°rio:")
        if col1.button("üò° Cliente Irritado"):
            suggestion = "Inicie uma simula√ß√£o onde voc√™ √© um cliente furioso porque a entrega atrasou. Eu sou o gerente."
        if col2.button("üíº Chefe Exigente"):
            suggestion = "Atue como meu chefe pedindo cortes de or√ßamento imposs√≠veis. Eu preciso defender meu time."
        if col3.button("ü§ë Investidor C√©tico"):
            suggestion = "Voc√™ √© um investidor Shark Tank. Eu estou tentando vender minha ideia. Comece me questionando."

    # Se clicou em algum bot√£o, j√° envia a mensagem
    if suggestion:
        st.session_state.messages.append({"role": "user", "content": suggestion})
        st.rerun()

# --- EXIBI√á√ÉO DO CHAT ---
else:
    # Mostra t√≠tulo menor quando j√° tem chat
    st.subheader(f"Conversando com: Mentor ({mode})")

for message in st.session_state.messages:
    avatar = "ü§ñ" if message["role"] == "assistant" else "üë§"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# Input do Usu√°rio
if prompt := st.chat_input("Digite sua d√∫vida ou resposta..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="üë§"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ü§ñ"):
        with st.spinner("Consultando material de Harvard..."):
            response_text = get_gemini_response(st.session_state.messages, mode, pdf_text)
            st.markdown(response_text)
            st.session_state.messages.append({"role": "assistant", "content": response_text})
