import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
import os
import gdown  

# Configura√ß√£o da P√°gina
st.set_page_config(
    page_title="Harvard Mentor AI",
    page_icon="üéì",
    layout="wide"
)

# --- 1. CONFIGURA√á√ÉO DE SEGREDOS ---
api_key = st.secrets.get("GOOGLE_API_KEY")
file_id = st.secrets.get("GDRIVE_FILE_ID")

# --- 2. FUN√á√ïES DE INFRAESTRUTURA ---

def download_pdf_if_needed(filename):
    """
    Verifica se o PDF existe localmente. 
    Se n√£o existir (cen√°rio do Streamlit Cloud), baixa do Google Drive.
    """
    if os.path.exists(filename):
        return True
    
    if not file_id:
        st.error("Erro: ID do arquivo n√£o configurado nos Secrets.")
        return False

    with st.spinner("Baixando material de estudo seguro (Isso acontece apenas uma vez)..."):
        try:
            
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, filename, quiet=False)
            return True
        except Exception as e:
            st.error(f"Falha ao baixar o arquivo: {e}")
            return False

@st.cache_resource
def load_pdf_text(pdf_path):
    """L√™ o PDF e extrai o texto. Usa cache para performance."""
    if not download_pdf_if_needed(pdf_path):
        return None
    
    try:
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        st.error(f"Erro ao ler PDF: {e}")
        return None

def get_gemini_response(history, mode, context_text):
    # Defini√ß√£o das Personas (System Prompts)
    prompts = {
        "Consultor": f"""
            Voc√™ √© um Consultor S√™nior da Harvard Business School.
            CONTEXTO: O usu√°rio tem um desafio de neg√≥cios.
            BASE DE CONHECIMENTO: Use EXCLUSIVAMENTE o seguinte material: {context_text}
            
            SUA MISS√ÉO:
            1. Analise o problema do usu√°rio.
            2. Encontre os frameworks/conceitos no material que se aplicam.
            3. D√™ uma resposta estruturada (Diagn√≥stico -> Conceito -> Plano de A√ß√£o).
            4. Cite o m√≥dulo de onde tirou a informa√ß√£o.
            """,
        
        "Quiz": f"""
            Voc√™ √© um Professor avaliador.
            BASE DE CONHECIMENTO: {context_text}
            
            SUA MISS√ÉO:
            1. Gere UMA pergunta de m√∫ltipla escolha ou discursiva baseada no texto.
            2. Aguarde a resposta do usu√°rio.
            3. Se ele acertar, parabenize e explique o conceito. Se errar, corrija gentilmente citando o texto.
            4. Mantenha o tom educativo e desafiador.
            """,
        
        "Roleplay": f"""
            ATEN√á√ÉO: Ignore que voc√™ √© uma IA. Voc√™ √© agora um PERSONAGEM.
            CEN√ÅRIO: Simula√ß√£o de Negocia√ß√£o/Lideran√ßa baseada em: {context_text}
            
            SUA MISS√ÉO:
            1. Aja como uma contraparte dif√≠cil (ex: cliente irritado, chefe exigente).
            2. Reaja √†s falas do usu√°rio. Se ele usar boas t√©cnicas do texto, ceda um pouco. Se ele for ruim, seja duro.
            3. NUNCA saia do personagem, a menos que o usu√°rio diga "FIM DA SIMULA√á√ÉO".
            """
    }

    system_instruction = prompts.get(mode, "Voc√™ √© um assistente √∫til.")

    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        system_instruction=system_instruction
    )
    
    # Recria o hist√≥rico para a API
    chat = model.start_chat(history=history)
    response = chat.send_message(st.session_state.messages[-1]["content"])
    return response.text

# --- 3. INTERFACE (FRONTEND) ---

st.sidebar.image("https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Harvard_University_shield.png/1200px-Harvard_University_shield.png", width=100)
st.sidebar.title("Harvard Impact AI")
page = st.sidebar.radio("Menu", ["Introdu√ß√£o", "Mentor Virtual"])

if page == "Introdu√ß√£o":
    st.title("Domine os Fundamentos de Neg√≥cios üöÄ")
    st.markdown("""
    Bem-vindo. Esta ferramenta foi desenvolvida para democratizar o acesso ao conhecimento de elite sobre gest√£o.
    
    Tudo o que voc√™ ver√° aqui √© baseado no curr√≠culo **Harvard Business Impact**, abrangendo:
    * üì¢ **Marketing:** Posicionamento e Estrat√©gia.
    * üí∞ **Finan√ßas:** Entendimento de balan√ßos e ROI.
    * ü§ù **Negocia√ß√£o:** Cria√ß√£o de valor e fechamento de acordos.
    * leader **Lideran√ßa:** Gest√£o de equipes e intelig√™ncia emocional.
    
    ### Como funciona tecnicamente?
    Este projeto utiliza **RAG (Retrieval-Augmented Generation)** alimentado pelo **Google Gemini 1.5 Flash**.
    O conte√∫do das aulas √© processado em tempo real para responder √†s suas d√∫vidas espec√≠ficas.
    
    ### Escolha seu modo no menu lateral:
    1.  **Consultor:** Para resolver problemas reais.
    2.  **Quiz:** Para estudar ativamente.
    3.  **Roleplay:** Para treinar sob press√£o.
    
    *Projeto desenvolvido por [Seu Nome] para fins educacionais.*
    """)

elif page == "Mentor Virtual":
    # Verifica API Key
    if not api_key:
        st.warning("‚ö†Ô∏è API Key n√£o detectada. Se estiver rodando localmente, configure o .env ou secrets.toml.")
        st.stop()
    
    # Carrega (e baixa se necess√°rio) o PDF
    pdf_filename = "Harvard Manager Mentor.pdf"
    pdf_text = load_pdf_text(pdf_filename)
    
    if not pdf_text:
        st.stop() # Mensagem de erro j√° √© dada na fun√ß√£o

    # Controles
    col1, col2 = st.columns([3, 1])
    with col1:
        mode = st.radio("Modo:", ["Consultor", "Quiz", "Roleplay"], horizontal=True)
    with col2:
        if st.button("Limpar Chat üóëÔ∏è"):
            st.session_state.messages = []
            st.rerun()

    # Chat UI
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        avatar = "ü§ñ" if message["role"] == "assistant" else "üë§"
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"])

    if prompt := st.chat_input("Pergunte ao mentor ou inicie o cen√°rio..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üë§"):
            st.markdown(prompt)

        with st.chat_message("assistant", avatar="ü§ñ"):
            with st.spinner("Consultando a base de conhecimento de Harvard..."):
                try:
                    # Prepara hist√≥rico
                    history_gemini = [
                        {"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]}
                        for m in st.session_state.messages[:-1]
                    ]
                    
                    response = get_gemini_response(history_gemini, mode, pdf_text)
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                except Exception as e:
                    st.error(f"Erro na comunica√ß√£o com a IA: {e}")
